{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id=\"is3107-news\"\n",
    "\n",
    "TableId_FilePath_dict={\n",
    "    \"Tickers\":\"../company_news/tickers.json\",\n",
    "    \"Company\":\"../Company/Company.csv\",\n",
    "    \"FinanceSituation\":\"../Finance_situation/Finance_situation.csv\",\n",
    "    \"StockData\":\"../stock_price/stock_price.csv\",\n",
    "    \"News\":\"../company_news/news2.csv\",\n",
    "}\n",
    "\n",
    "# file path after transfering process\n",
    "# News and FinanceSituation are transfered\n",
    "TableId_FilePath_dict_trans={\n",
    "    \"Tickers\":\"../company_news/tickers.csv\",\n",
    "    \"Company\":\"../Company/Company.csv\",\n",
    "    \"FinanceSituation\":\"../Finance_situation/Finance_situation_trans.csv\",\n",
    "    \"StockData\":\"../stock_price/stock_price.csv\",\n",
    "    \"News\":\"../company_news/news2_trans.csv\",\n",
    "}\n",
    "\n",
    "TableId_PrimaryKey_dict={\n",
    "    \"Tickers\":[\"ticker\",\"news_id\"],\n",
    "    \"Company\":[\"id\"],\n",
    "    \"FinanceSituation\":[\"company_id\"],\n",
    "    \"StockData\":[\"Ticker\",\"Date\"],\n",
    "    \"News\":[\"id\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build stock-news relation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_columns=[\"ticker\",\"news_id\"]\n",
    "# df_tickers.head()\n",
    "rows=[]\n",
    "with open(TableId_FilePath_dict[\"Tickers\"], 'r') as file:\n",
    "    data = json.load(file)\n",
    "    # print(data)\n",
    "    \n",
    "    for stock,news_list in data.items():\n",
    "        for news_id in news_list:\n",
    "            rows.append([stock,news_id])\n",
    "df_relation=pd.DataFrame(rows,columns=relation_columns)\n",
    "df_relation.to_csv(TableId_FilePath_dict_trans[\"Tickers\"],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>news_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>175557073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>175592149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>175725585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>175559319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>175585505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36895</th>\n",
       "      <td>NRG</td>\n",
       "      <td>175582467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36896</th>\n",
       "      <td>NRG</td>\n",
       "      <td>175577659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36897</th>\n",
       "      <td>NRG</td>\n",
       "      <td>175585095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36898</th>\n",
       "      <td>NRG</td>\n",
       "      <td>175577749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36899</th>\n",
       "      <td>NRG</td>\n",
       "      <td>175578023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36900 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ticker    news_id\n",
       "0      GOOGL  175557073\n",
       "1      GOOGL  175592149\n",
       "2      GOOGL  175725585\n",
       "3      GOOGL  175559319\n",
       "4      GOOGL  175585505\n",
       "...      ...        ...\n",
       "36895    NRG  175582467\n",
       "36896    NRG  175577659\n",
       "36897    NRG  175585095\n",
       "36898    NRG  175577749\n",
       "36899    NRG  175578023\n",
       "\n",
       "[36900 rows x 2 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data transfering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the index column in stock_price.csv\n",
    "df_stock_price=pd.read_csv(TableId_FilePath_dict[\"StockData\"],usecols=[\"Ticker\",\"Date\",\"log_return\"])\n",
    "df_stock_price.to_csv(TableId_FilePath_dict_trans[\"StockData\"],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news csv\n",
    "# filter chinese character\n",
    "df_news=pd.read_csv(TableId_FilePath_dict[\"News\"])\n",
    "\n",
    "#time stamp to data time\n",
    "df_news[\"publish_date\"]=pd.to_datetime(df_news[\"publish_date\"])\n",
    "df_news[\"publish_date\"]=df_news[\"publish_date\"].dt.date\n",
    "df_news.to_csv(TableId_FilePath_dict_trans[\"News\"],index=False)\n",
    "\n",
    "def contains_chinese(text):\n",
    "    for char in text:\n",
    "        if char>='\\u4e00' and char<='\\u9fff':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "df_filter_title=df_news[~df_news[\"title\"].apply(contains_chinese)]\n",
    "df_filter_text=df_news[~df_news[\"text\"].apply(contains_chinese)]\n",
    "df_filter_text=df_filter_text.drop_duplicates(subset='id',keep=\"first\")\n",
    "df_filter_text.to_csv(TableId_FilePath_dict_trans[\"News\"],index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 11)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filter_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finance_situation.csv\n",
    "df_fin=pd.read_csv(TableId_FilePath_dict[\"FinanceSituation\"])\n",
    "df_fin[\"debtToEquity\"]/=100\n",
    "df_fin[\"debtToEquity\"].fillna(0,inplace=True)\n",
    "df_fin.to_csv(TableId_FilePath_dict_trans[\"FinanceSituation\"],index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data to cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "dataset_id = 'raw_data'\n",
    "dataset_ref = client.dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(tmp_table_id,target_table_id):\n",
    "\n",
    "    primarykey_list=TableId_PrimaryKey_dict[target_table_id.split('.')[-1]]\n",
    "    \n",
    "    if len(primarykey_list)==1:\n",
    "        primarykey_statement=f\"target.{primarykey_list[0]} = source.{primarykey_list[0]}\"\n",
    "    elif len(primarykey_list)==2:\n",
    "        primarykey_statement=f\"target.{primarykey_list[0]} = source.{primarykey_list[0]} \"+\\\n",
    "            f\" AND target.{primarykey_list[1]} = source.{primarykey_list[1]}\"\n",
    "        \n",
    "    \n",
    "    merge_statement=f\"\"\"\n",
    "    MERGE `{target_table_id}` AS target\n",
    "    USING `{tmp_table_id}` AS source\n",
    "    ON ({primarykey_statement})\n",
    "    WHEN NOT MATCHED THEN\n",
    "        INSERT ROW\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    query_job = client.query(merge_statement)\n",
    "\n",
    "    # 等待任务完成\n",
    "    query_job.result()\n",
    "\n",
    "def load_data(table_id,file_path):\n",
    "    # this is autodectect schema mode\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        source_format=bigquery.SourceFormat.CSV, skip_leading_rows=1, autodetect=True,\n",
    "    )\n",
    "    \n",
    "    #upload the tmp table\n",
    "    tmp_table_id=table_id+\"_tmp\"\n",
    "    with open(file_path, \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(source_file, tmp_table_id, job_config=job_config)\n",
    "    job.result()  # Waits for the job to complete.\n",
    "    \n",
    "    merge_data(tmp_table_id,table_id)\n",
    "    # drop the tmp table\n",
    "    client.delete_table(tmp_table_id)\n",
    "    \n",
    "    table = client.get_table(table_id)  # Make an API request.\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {}\".format(\n",
    "            table.num_rows, len(table.schema), table_id\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_id,file_path in TableId_FilePath_dict_trans.items():\n",
    "    print(f\"Load data: {table_id}:\")\n",
    "    load_data(f\"{project_id}.{dataset_id}.{table_id}\",file_path)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SQL**\n",
    "\n",
    "DELETE FROM `is3107-news.raw_data.News`\n",
    "\n",
    "WHERE id IN (\n",
    "\n",
    "    SELECT id\n",
    "\n",
    "    FROM `is3107-news.raw_data.News`\n",
    "\n",
    "    LIMIT 10 -- 删除前10行\n",
    "\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table ID: Company\n",
      "Table ID: FinanceSituation\n",
      "Table ID: Industry\n",
      "Table ID: News\n",
      "Table ID: StockData\n",
      "Table ID: Tickers\n",
      "Table ID: raw_news\n",
      "Table ID: raw_news_test\n"
     ]
    }
   ],
   "source": [
    "tables = client.list_tables(dataset_ref)\n",
    "for table in tables:\n",
    "    print(\"Table ID: {}\".format(table.table_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables contained in 'raw_data':\n",
      "Table ID: Company\n",
      "Schema of 'Company':\n",
      "Column name: id, Column type: STRING\n",
      "Column name: name, Column type: STRING\n",
      "Column name: fullTimeEmployees, Column type: FLOAT\n",
      "Column name: Industry, Column type: STRING\n",
      "Column name: Country, Column type: STRING\n",
      "Preview of the first few rows from 'Company':\n",
      "     id                             name  fullTimeEmployees  \\\n",
      "0  LULU         lululemon athletica inc.            38000.0   \n",
      "1   MDT                   Medtronic plc.            95000.0   \n",
      "2   STE             STERIS plc (Ireland)            17000.0   \n",
      "3   ACN                    Accenture plc           742000.0   \n",
      "4   STX  Seagate Technology Holdings PLC            33400.0   \n",
      "\n",
      "            Industry  Country  \n",
      "0  Consumer Cyclical   Canada  \n",
      "1         Healthcare  Ireland  \n",
      "2         Healthcare  Ireland  \n",
      "3         Technology  Ireland  \n",
      "4         Technology  Ireland  \n",
      "\n",
      "\n",
      "Table ID: FinanceSituation\n",
      "Schema of 'FinanceSituation':\n",
      "Column name: company_id, Column type: STRING\n",
      "Column name: AuditRisk, Column type: FLOAT\n",
      "Column name: Dividend_rate, Column type: FLOAT\n",
      "Column name: Dividend_Yield, Column type: FLOAT\n",
      "Column name: Payout_rate, Column type: FLOAT\n",
      "Column name: Beta, Column type: FLOAT\n",
      "Column name: Market_Cap, Column type: FLOAT\n",
      "Column name: profit_margins, Column type: FLOAT\n",
      "Column name: short_ratio, Column type: FLOAT\n",
      "Column name: quick_ratio, Column type: FLOAT\n",
      "Column name: current_ratio, Column type: FLOAT\n",
      "Column name: debtToEquity, Column type: FLOAT\n",
      "Preview of the first few rows from 'FinanceSituation':\n",
      "  company_id  AuditRisk  Dividend_rate  Dividend_Yield  Payout_rate   Beta  \\\n",
      "0       SOLV        NaN            NaN             NaN          NaN    NaN   \n",
      "1        KMX        2.0            NaN             NaN          NaN  1.598   \n",
      "2       DXCM        2.0            NaN             NaN          NaN  1.207   \n",
      "3         ON        2.0            NaN             NaN          NaN  1.790   \n",
      "4        PTC        2.0            NaN             NaN          NaN  1.184   \n",
      "\n",
      "   Market_Cap  profit_margins  short_ratio  quick_ratio  current_ratio  \\\n",
      "0    0.239867         0.16421          NaN        0.872          1.458   \n",
      "1    0.231860         0.01763        12.57        0.393          2.453   \n",
      "2    1.183405         0.14949         4.32        2.385          2.844   \n",
      "3    0.221613         0.26459         3.51        1.604          2.708   \n",
      "4    0.159129         0.10860         2.84        0.992          1.194   \n",
      "\n",
      "   debtToEquity  \n",
      "0       0.00840  \n",
      "1       3.26105  \n",
      "2       1.25399  \n",
      "3       0.46455  \n",
      "4       0.87324  \n",
      "\n",
      "\n",
      "Table ID: Industry\n",
      "Schema of 'Industry':\n",
      "Column name: Industry, Column type: STRING\n",
      "Column name: sentiment, Column type: FLOAT\n",
      "Column name: AuditRisk, Column type: FLOAT\n",
      "Column name: Dividend_rate, Column type: FLOAT\n",
      "Column name: Dividend_Yield, Column type: FLOAT\n",
      "Column name: Payout_rate, Column type: FLOAT\n",
      "Column name: Beta, Column type: FLOAT\n",
      "Column name: Market_Cap, Column type: FLOAT\n",
      "Column name: profit_margins, Column type: FLOAT\n",
      "Column name: short_ratio, Column type: FLOAT\n",
      "Column name: quick_ratio, Column type: FLOAT\n",
      "Column name: current_ratio, Column type: FLOAT\n",
      "Column name: debtToEquity, Column type: FLOAT\n",
      "Preview of the first few rows from 'Industry':\n",
      "                 Industry  sentiment  AuditRisk  Dividend_rate  \\\n",
      "0             Real Estate   0.116459   3.963466       4.351176   \n",
      "1         Basic Materials   0.111697   5.313537       2.546480   \n",
      "2      Consumer Defensive   0.101209   6.460432       2.809065   \n",
      "3  Communication Services   0.103378   8.243243       1.901290   \n",
      "4               Utilities   0.105863   5.550404       2.418199   \n",
      "\n",
      "   Dividend_Yield  Payout_rate      Beta  Market_Cap  profit_margins  \\\n",
      "0        0.042388     6.065708  1.008858    3.943284        0.215055   \n",
      "1        0.021149     0.579976  1.138445    7.309371        0.107478   \n",
      "2        0.032622     0.574449  0.671180    2.410699        0.119740   \n",
      "3        0.030611     0.654987  1.132978   24.288739        0.149642   \n",
      "4        0.037287     0.674349  0.632805    4.577116        0.120373   \n",
      "\n",
      "   short_ratio  quick_ratio  current_ratio  debtToEquity  \n",
      "0     3.073742     2.270948       2.517077      2.817140  \n",
      "1     2.565834     1.221592       1.962254      0.680893  \n",
      "2     2.325899     0.310806       0.688338      0.863004  \n",
      "3     2.794973     1.546751       1.727135      0.494602  \n",
      "4     2.532394     0.395478       0.797209      1.765473  \n",
      "\n",
      "\n",
      "Table ID: News\n",
      "Schema of 'News':\n",
      "Column name: id, Column type: INTEGER\n",
      "Column name: title, Column type: STRING\n",
      "Column name: text, Column type: STRING\n",
      "Column name: url, Column type: STRING\n",
      "Column name: image, Column type: STRING\n",
      "Column name: publish_date, Column type: DATE\n",
      "Column name: author, Column type: STRING\n",
      "Column name: authors, Column type: STRING\n",
      "Column name: language, Column type: STRING\n",
      "Column name: source_country, Column type: STRING\n",
      "Column name: sentiment, Column type: FLOAT\n",
      "Preview of the first few rows from 'News':\n",
      "          id                                              title  \\\n",
      "0  175560657  Indian athletes to aim at Paris Olympics this ...   \n",
      "1  175560893  Couple treat pet pigs to bubble baths and orga...   \n",
      "2  175554459  New year, new job! As Crown Princess Mary of D...   \n",
      "3  175556823  New year: Fireworks and street parties ring in...   \n",
      "4  175557073  Farmers caught in the growing competition for ...   \n",
      "\n",
      "                                                text  \\\n",
      "0  New Delhi [India], January 1 (ANI): The domest...   \n",
      "1  Meet the pampered pigs who are treated to bubb...   \n",
      "2  Crown Princess Mary is preparing for her role ...   \n",
      "3  The UK marked the beginning of 2024 with firew...   \n",
      "4  Throughout last year (2023), the climate chang...   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://www.thejapannews.net/news/274081732/in...   \n",
      "1  https://www.dailyrecord.co.uk/news/uk-world-ne...   \n",
      "2  https://www.dailymail.co.uk/femail/article-129...   \n",
      "3             https://www.bbc.co.uk/news/uk-67855970   \n",
      "4  https://www.agriland.ie/farming-news/farmers-c...   \n",
      "\n",
      "                                               image publish_date  \\\n",
      "0   https://cdn.bignewsnetwork.com/ani1704098637.jpg   2024-01-01   \n",
      "1  https://i2-prod.dailyrecord.co.uk/incoming/art...   2024-01-01   \n",
      "2  https://i.dailymail.co.uk/1s/2024/01/01/10/795...   2024-01-01   \n",
      "3  https://ichef.bbci.co.uk/news/1024/branded_new...   2024-01-01   \n",
      "4  https://cdn.agriland.ie/uploads/2023/12/DSC_24...   2024-01-01   \n",
      "\n",
      "                       author                           authors language  \\\n",
      "0                        None                                []       en   \n",
      "1                   Emma Dunn                     ['Emma Dunn']       en   \n",
      "2   Editor, Elmira Tanatarova   ['Editor', 'Elmira Tanatarova']       en   \n",
      "3               Doug Faulkner                 ['Doug Faulkner']       en   \n",
      "4  Jeff Bezos, Justin Roberts  ['Jeff Bezos', 'Justin Roberts']       en   \n",
      "\n",
      "  source_country  sentiment  \n",
      "0             bh      0.068  \n",
      "1             gb      0.437  \n",
      "2             gb      0.426  \n",
      "3             gb      0.380  \n",
      "4             ie      0.149  \n",
      "\n",
      "\n",
      "Table ID: StockData\n",
      "Schema of 'StockData':\n",
      "Column name: Ticker, Column type: STRING\n",
      "Column name: Date, Column type: DATE\n",
      "Column name: log_return, Column type: FLOAT\n",
      "Preview of the first few rows from 'StockData':\n",
      "  Ticker        Date  log_return\n",
      "0  GOOGL  2024-01-02         NaN\n",
      "1   MTCH  2024-01-02         NaN\n",
      "2   META  2024-01-02         NaN\n",
      "3   NFLX  2024-01-02         NaN\n",
      "4    OMC  2024-01-02         NaN\n",
      "\n",
      "\n",
      "Table ID: Tickers\n",
      "Schema of 'Tickers':\n",
      "Column name: ticker, Column type: STRING\n",
      "Column name: news_id, Column type: INTEGER\n",
      "Preview of the first few rows from 'Tickers':\n",
      "  ticker    news_id\n",
      "0  GOOGL  175586561\n",
      "1  GOOGL  175586561\n",
      "2  GOOGL  175586561\n",
      "3  GOOGL  175678977\n",
      "4  GOOGL  175678977\n",
      "\n",
      "\n",
      "Table ID: raw_news\n",
      "Schema of 'raw_news':\n",
      "Preview of the first few rows from 'raw_news':\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "\n",
      "Table ID: raw_news_test\n",
      "Schema of 'raw_news_test':\n",
      "Column name: author, Column type: STRING\n",
      "Column name: title, Column type: STRING\n",
      "Column name: description, Column type: STRING\n",
      "Column name: url, Column type: STRING\n",
      "Column name: urlToImage, Column type: STRING\n",
      "Column name: publishedAt, Column type: STRING\n",
      "Column name: content, Column type: STRING\n",
      "Column name: source_id, Column type: STRING\n",
      "Column name: source_name, Column type: STRING\n",
      "Preview of the first few rows from 'raw_news_test':\n",
      "              author                                              title  \\\n",
      "0  InvestorsObserver  PowerBand Receives TSXV Approval for Extension...   \n",
      "1      coinpedia.org  Analyst Predicts XRP’s Ascent to $1; Breakout ...   \n",
      "2      coinpedia.org  Destroyer, Set To Release New ‘Black Account’ ...   \n",
      "3                TNN  Law should keep pace with fintech and digitisa...   \n",
      "4      coinpedia.org  The Bull Run of 2024 and Why Launchpad Tokens ...   \n",
      "\n",
      "                                         description  \\\n",
      "0  TORONTO, ON / ACCESSWIRE / March 25, 2024 /  P...   \n",
      "1  The post Analyst Predicts XRP’s Ascent to $1; ...   \n",
      "2  Destroyer, Set To Release New ‘Black Account’ ...   \n",
      "3  CHENNAI: The rapid digitalisation of finance b...   \n",
      "4  The post The Bull Run of 2024 and Why Launchpa...   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://www.investorsobserver.com/news/qm-pr/5...   \n",
      "1              https://biztoc.com/x/137345cdf62dc983   \n",
      "2              https://biztoc.com/x/6a2ee8963019cb33   \n",
      "3  https://timesofindia.indiatimes.com/city/chenn...   \n",
      "4              https://biztoc.com/x/187bdc722813c83d   \n",
      "\n",
      "                                          urlToImage           publishedAt  \\\n",
      "0  https://s3.amazonaws.com/images.investorsobser...  2024-03-25T15:30:00Z   \n",
      "1     https://c.biztoc.com/p/137345cdf62dc983/s.webp  2024-03-25T15:28:36Z   \n",
      "2     https://c.biztoc.com/p/6a2ee8963019cb33/s.webp  2024-03-25T15:28:33Z   \n",
      "3  https://static.toiimg.com/thumb/msid-108770087...  2024-03-25T15:16:39Z   \n",
      "4     https://c.biztoc.com/p/187bdc722813c83d/s.webp  2024-03-25T15:12:52Z   \n",
      "\n",
      "                                             content           source_id  \\\n",
      "0  News HomeMentioned in this article\\r\\nTORONTO,...                None   \n",
      "1  The post Analyst Predicts XRPs Ascent to $1; B...                None   \n",
      "2  Destroyer, Set To Release New Black Account Fe...                None   \n",
      "3              8 fruits that help lose weight faster  the-times-of-india   \n",
      "4  The post The Bull Run of 2024 and Why Launchpa...                None   \n",
      "\n",
      "          source_name  \n",
      "0   InvestorsObserver  \n",
      "1          Biztoc.com  \n",
      "2          Biztoc.com  \n",
      "3  The Times of India  \n",
      "4          Biztoc.com  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check all the tables\n",
    "\n",
    "# API \n",
    "tables = client.list_tables(dataset_ref)\n",
    "\n",
    "print(\"Tables contained in '{}':\".format(dataset_id))\n",
    "for table in tables:\n",
    "    print(\"Table ID: {}\".format(table.table_id))\n",
    "\n",
    "    table_ref = dataset_ref.table(table.table_id)\n",
    "    table = client.get_table(table_ref)  \n",
    "\n",
    "    # show the column and the dtype\n",
    "    print(\"Schema of '{}':\".format(table.table_id))\n",
    "    for schema_field in table.schema:\n",
    "        print(\"Column name: {}, Column type: {}\".format(schema_field.name, schema_field.field_type))\n",
    "\n",
    "    # view few rows from the table\n",
    "    preview = client.list_rows(table, max_results=5).to_dataframe()\n",
    "    print(\"Preview of the first few rows from '{}':\".format(table.table_id))\n",
    "    print(preview)\n",
    "    print(\"\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete table\n",
    "\n",
    "# for table_id,file_path in TableId_FilePath_dict_trans.items():\n",
    "#     full_table_id = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "#     client.delete_table(full_table_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
